{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff2fa2e",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "In this exercise I will explore how a decision tree is splitted using [Information Gain](https://en.wikipedia.org/wiki/Information_gain_(decision_tree)).\n",
    "\n",
    "In Decision Tree, we decide if a node will be split or not by looking at the **Information Gain** that split would give us.\n",
    "\n",
    "$$ Information \\; Gain = H(p_1^{node}) - \\left( w^{left} H(p_1^{left}) + w^{right} H(p_1^{right}) \\right)$$\n",
    "\n",
    "Where $H$ is the entropy, defined as:\n",
    "\n",
    "$$ H(p_1) = -p_1 \\log_2 (p_1) - (1-p_1) \\log_2 (1-p_1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9540fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d65c98",
   "metadata": {},
   "source": [
    "The data I will use is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192a5abf",
   "metadata": {},
   "source": [
    "|               | Ear Shape | Face Shape | Whiskers|   Cat |\n",
    "|:-------------:|:---------:|:----------:|:-------:|:-----:|\n",
    "|<img src=\"images/0.png\" alt=\"drawing\" width=\"50\"> | Pointy | Round     | Present | 1 |\n",
    "|<img src=\"images/1.png\" alt=\"drawing\" width=\"50\"> | Floppy | Not Round | Present | 1 |\n",
    "|<img src=\"images/2.png\" alt=\"drawing\" width=\"50\"> | Floppy | Round     | Absent  | 0 |\n",
    "|<img src=\"images/3.png\" alt=\"drawing\" width=\"50\"> | Pointy | Not Round | Present | 0 |\n",
    "|<img src=\"images/4.png\" alt=\"drawing\" width=\"50\"> | Pointy | Round     | Present | 1 |\n",
    "|<img src=\"images/5.png\" alt=\"drawing\" width=\"50\"> | Pointy | Round     | Absent  | 1 |\n",
    "|<img src=\"images/6.png\" alt=\"drawing\" width=\"50\"> | Floppy | Not Round | Absent  | 0 |\n",
    "|<img src=\"images/7.png\" alt=\"drawing\" width=\"50\"> | Pointy | Round     | Absent  | 1 |\n",
    "|<img src=\"images/8.png\" alt=\"drawing\" width=\"50\"> | Floppy | Round     | Absent  | 0 |\n",
    "|<img src=\"images/9.png\" alt=\"drawing\" width=\"50\"> | Floppy | Round     | Absent  | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3b7ad",
   "metadata": {},
   "source": [
    "I will use **one-hot encoding** to encode the categorical features.\n",
    "- Ear Shape: Pointy = 1, Floppy = 0\n",
    "- Face Shape: Round = 1, Not Round = 0\n",
    "- Whiskers: Present = 1, Absent = 0\n",
    "\n",
    "With this election, the dataset is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5707f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set\n",
    "X_train = np.array([[1,1,1],\n",
    "                   [0,0,1],\n",
    "                   [0,1,0],\n",
    "                   [1,0,1],\n",
    "                   [1,1,1],\n",
    "                   [1,1,0],\n",
    "                   [0,0,0],\n",
    "                   [1,1,0],\n",
    "                   [0,1,0],\n",
    "                   [0,1,0]])\n",
    "\n",
    "y_train = np.array([1,1,0,0,1,1,0,1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5b33fe",
   "metadata": {},
   "source": [
    "On each node, we compute the gain information for each feature, the split the node on the feature with the higher information gain, by comparing the entropy of the node wjth the weighted entropy in the two splitted nodes.\n",
    "\n",
    "Let's write a function to compute the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a220d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    if p == 0 or p ==1:\n",
    "        return 0\n",
    "    else:\n",
    "        H = -p * np.log2(p) - (1 - p)*np.log2(1 - p)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a60425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a708569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(X, index_features):\n",
    "    \"\"\"\n",
    "        Given a dataset and a index feature, return two lists for the two split nodes, the left node has the animals that have \n",
    "        that feature = 1 and the right node those that have the feature = 0 \n",
    "        index feature = 0 => ear shape\n",
    "        index feature = 1 => face shape\n",
    "        index feature = 2 => whiskers\n",
    "    \"\"\"\n",
    "\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        if x[index_features] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "    return left_indices, right_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1089c674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 3, 4, 5, 7], [1, 2, 6, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_indices(X_train, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40579bd0",
   "metadata": {},
   "source": [
    "If we see the table of values, we see that those values equal to 1 for the *ear shape* feature, second column, are returned in the **left_indices** list while the others are in the **right_indices** list.\n",
    "\n",
    "Now, we need another function to compute the weighted entropy in the splitted node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0075ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_entropy(X, y, left_indices, right_indices):\n",
    "    \"\"\"\n",
    "            This function takes the splitted dataset, the indices we chose to split and returns the weighted entropy.\n",
    "    \"\"\"\n",
    "\n",
    "    w_left = len(left_indices) / len(X)                         # Computes the proportion of animals in each node.\n",
    "    w_right = len(right_indices) / len(X)\n",
    "    p_left = sum(y[left_indices]) / len(left_indices)           # Computes the proportion of cats in each split.\n",
    "    p_right = sum(y[right_indices]) / ( len(right_indices))\n",
    "\n",
    "    weighted_entropy = w_left * entropy(p_left) + w_right * entropy(p_right)\n",
    "\n",
    "    return weighted_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ee3f576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7219280948873623"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_indices, right_indices = split_indices(X_train, 0)\n",
    "weighted_entropy(X_train, y_train, left_indices, right_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c01a3c",
   "metadata": {},
   "source": [
    "So, the weighted entropy in the 2 split nodes is $\\approx 0.72$. To computhe the **Information Gain ** we must substract it from the entropy in the node we chose to split (in this case the root node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fd3be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(X, y, left_indices, right_indices):\n",
    "    \"\"\"\n",
    "            Here, X has the elements in the node and y is theirs respectives classes\n",
    "    \"\"\"\n",
    "\n",
    "    p_node = sum(y) / len(y)\n",
    "    h_node = entropy(p_node)\n",
    "    w_entropy = weighted_entropy(X, y, left_indices, right_indices)\n",
    "    return h_node - w_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccfc2dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2780719051126377"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain(X_train, y_train, left_indices, right_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55205a5c",
   "metadata": {},
   "source": [
    "Now, let's compute the information gain if we split the root node for each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c79c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Ear Shape, information gain if we split the root using this feature: 0.28\n",
      "Feature: Face Shape, information gain if we split the root using this feature: 0.03\n",
      "Feature: Whiskers, information gain if we split the root using this feature: 0.12\n"
     ]
    }
   ],
   "source": [
    "for i, feature_name in enumerate(['Ear Shape', 'Face Shape', 'Whiskers']):\n",
    "    left_indices, right_indices = split_indices(X_train, i)\n",
    "    i_gain = information_gain(X_train, y_train, left_indices, right_indices)\n",
    "    print(f\"Feature: {feature_name}, information gain if we split the root using this feature: {i_gain:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e6757",
   "metadata": {},
   "source": [
    "So, the best feature to split is indeed the **Ear Shape**.\n",
    "\n",
    "The process is **recursive**, which means we must perform these calculations for each node until we meet a stopping criteria:\n",
    "\n",
    "- If the tree depth after splitting exceeds a threshold\n",
    "- If the resulting node has only 1 class\n",
    "- If the information gain of splitting is below a threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e012b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
